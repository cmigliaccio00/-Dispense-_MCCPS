\documentclass[a4paper, 12pt]{article}

\usepackage{graphicx}
\usepackage{titlesec}
\usepackage{xcolor}
\usepackage{amsfonts}
\usepackage{wrapfig}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{glossaries}


%\titlespacing*{\title}{0pt}{20pt}{200pt}
%\titlespacing*{\date}{0pt}{0ex}{0ex}
%\titlespacing*{\author}{0pt}{0ex}{0ex}

\titlespacing*{\section}{0pt}{0ex}{0ex}
\titlespacing*{\subsection}{0pt}{0ex}{0ex}
%\titlespacing\author{0pt}{0pt}{0pt}
%\titlespacing\date{0pt}{0pt}{0pt}
%\pagestyle{headings}
%\thispagestyle{headings}

\usepackage{graphicx} % Required for inserting images
\usepackage[a4paper, top=1cm, left=1.5cm, bottom=1.5cm, right=1.5cm]{geometry}

\title{
    \vspace{-1.5cm}
    \textbf{
        \large{
            \underline{MODELING AND CONTROL OF CYBER-PHYSICAL SYSTEMS}
   \vspace{-10ex}
        }
    }
}
\author{}
\date{}

\begin{document}
\maketitle
\vspace{0.15cm}
\section{Modeling of Cyber-Physical Systems}

%============================   1   ===================
{\color{red} \subsection*{Mathematical modeling for CPS}}
CPSs $\overset{\text{set of devices that}}{\longrightarrow}$ 
$\begin{cases}
    \text{inter-communicate}\\
    \text{compute}\\
    \text{interact with the physical-world}
\end{cases} 
    $ $\overset{\text{math models}}{\Longrightarrow}$
$
\begin{cases}
    \text{Hybrid systems {\small(dynamic switching)}}\\
    \text{CPSs under attacks (\textbf{Part I})}\\ 
    \text{Multi-agent systems (\textbf{Part II})}
\end{cases}
$\\
\textbf{CPS under attacks (on the sensors)} $\longrightarrow$ 
$\begin{cases}
    x(k+1)=Ax(k)\\
    y(k)=Cx(k)+a(k)
\end{cases}$  no $u(k)$, no $b(k)$(actuators)
$A \in \mathbb{R}^{n,n}, \quad C \in \mathbb{R}^{q,n} \quad 
a(k)\in \mathbb{R}^q, \quad q=\text{number of sensors}$\\

%============================= 2 =====================
{\color{red} \subsection*{Secure State Estimation of CPSs \quad\quad {\small{[FUSION CENTER]}}}} 
\underline{\textbf{Without attacks}} Observability $\iff$ $rank(\mathcal{O}_n)=n$, $\mathcal{O}_n=[C \ CA \ ... \ CA^{n-1}]^T$ (observability matrix) $\Rightarrow$ $x(0)$ found by pseudo-inversion of the system ${y=\mathcal{O}_nx(0)} \longrightarrow x(0)=\mathcal{O}_n^{\dagger} \ y$\\
\noindent
\underline{\textbf{Presence of attacks}} no model for the attacks $\Longrightarrow$ $\begin{cases}
    y(0)=Cx(0)+a(0)\\
    y(1)=CAx(0)+a(1)\\
    \vdots \quad \quad \quad \vdots\\
    y(T)=CA^{T-1}x(0)+a(T)
\end{cases}$ {\small($\infty$ solutions)}\\
\vspace{0.2cm}\noindent
\textit{\textbf{Assumption (sparsity)}} $\Vert a \Vert_0 \le h \ll q$ (by adding this the problem may have a \textbf{unique solution})\\
\noindent
{\color{blue} \textbf{Under which conditions can we solve the problem?} 
$\rightarrow$ Simplification of the problem}\\
$A=I_n$ (the system is static) $\longrightarrow$ $x(k+1)=x(k)=x$ 
$\overset{\text{problem becomes}}{\longrightarrow}$
$y=Cx+a \quad \text{s.t.} \ \Vert a \Vert_0 \le h$ \\
\textbf{Prop(Correctability)} (resilience to h attacks) $\iff \forall z \in \mathbb{R}^n, \  \Vert \mathcal{O}_Tz\Vert_0>2h$\\
\textbf{A necessary condition for correctability...} {\small{
    $q\ge 2h+n $ $\begin{cases}
        \text{large $q$ is not sufficient}\\
        \text{a minimum $q$ is required}
    \end{cases}$
}}\\

\vspace{-0.2cm}
\noindent
{\color{blue}\textbf{How can I solve the problem?} $\rightarrow$ Reformulation of the problem}
\begin{enumerate}
    \itemsep-0.2em
    \item[0.] if \textbf{Correctable}, the Decoder
    {\color{red} $\mathcal{D}_0 \doteq \underset{x\in\mathbb{R}^n,a\in\mathbb{R}^q}{\min} \Vert a \Vert_0 \ \text{s.t.} \ y=Cx+a $ }corrects $h$ attacks; 
    \item $y=Cx+a+\text{noise} \longrightarrow y\sim Cx+a \longrightarrow \underset{x\in\mathbb{R}^n}{\min} \frac{1}{2}\Vert y-Cx \Vert_2^2$ (Least-Squares problem)
    \item $\ell_0$-norm $\Rightarrow$ bad function $\underset{\text{convex relaxation}}{\Longrightarrow}$ $\ell_1$-norm {\small(best convex approximation)$\leftarrow$ \textbf{promotes sparsity}}
\end{enumerate}
\vspace{-0.5cm}
(0)+(1)+(2) $\Longrightarrow$ 
{\color{red}
$z=\underset{x\in\mathbb{R}^n, a\in\mathbb{R}^q}{\text{argmin}}
\frac{1}{2} \Vert y-Gz \Vert_2^2 + \lambda \Vert a \Vert_1 \quad
G=(C \quad I), \ z=\begin{pmatrix} x\\a \end{pmatrix}
$
}  $\Longleftarrow \begin{cases}
        \text{convex and continuous}\\
        \text{\textbf{unconstrained}}\\
        \text{non differentiable in 0}
\end{cases}$\\
\textbf{(Partial) LASSO} $\overset{\text{solved by using}}{\longrightarrow}$ $x(k+1)=\mathbb{S}_{\lambda\tau}[x(k)+\tau C^T(y-Cx(k))]$ (\textbf{IST} algorithm), {\small{$k\rightarrow$  iteration}} \\$\Longleftarrow$
derived from the \textbf{alternating minimization of the surrogate functional} $\mathcal{R}(x,b)$\\
In general for CPSs $x$ is not sparse $\longrightarrow$ $\Lambda=(0,0,...,0,\lambda, \lambda,...,\lambda)$, $\lambda_i=0, \ i=1,...,n$\\

%------------------------------------------------------------
{\color{red}\subsection*{(Indoor) Localization by RSS-fingerprinting \quad\quad {\small{[FUSION CENTER]}}}}
\begin{enumerate}
    \itemsep0em
    \item[0.] \textbf{Init}: cell-grid discretization ($p$=\# of cells, $q$=\# of sensors, $N_t$=\# of targets)
    \item \textbf{Training phase}: Dictionary $D\in\mathbb{R}^{q,n}$ is built. Target in each cell + measurement
    \item \textbf{Runtime phase}: each sensor takes $y_i$ $\longrightarrow$ \textbf{Where are the targets?} $y=Dx+\eta, \ x_i\in\{0,1\}$\\
    $x_i=1 \rightarrow $ in the $i$-th cell there is a target $\Longrightarrow$ $\underset{x\in\{0,1\}^p}{\min} \Vert y-Dx \Vert_2^2$ (mixed-integer $\rightarrow$ NP-Hard)
    \vspace{-0.3cm}
    \begin{enumerate}
        \itemsep0em
        \item $x\in\{0,1\}^p$ $\underset{\text{relaxation}}{\longrightarrow}$ $x\in\mathbb{R}^p$ so that the problem is feasible; 
        \item $N_t \ll p \Rightarrow$ seeking of a \textbf{sparse solution} $\Longrightarrow$ LASSO  
    \end{enumerate} 
\end{enumerate}

\noindent
\textbf{(\#1) Localization without attacks} 
$x^*=\underset{x\in\mathbb{R}^p}{\min} \frac{1}{2} \Vert y-Dx \Vert_2^2 + \lambda \Vert x \Vert_1$ (ISTA can be used)\\
\noindent
\textbf{(\#2) Localization under sensor attacks}
$x^*=\underset{z\in\mathbb{R}^p}{\min} \frac{1}{2} \Vert y-Gz \Vert_2^2 + \lambda \Vert z \Vert_1, \ G=(D \ I), \ z=(x \ a)^T$\\

{\color{red} \subsection*{Dynamic Secure State Estimation of CPSs \quad\quad {\small{[FUSION CENTER]}}}}
\noindent
In general {\large{$A\ne I_n$}} $\Longrightarrow$ The system is moving and the static-batch approach is too slow\\
{\color{blue}\textbf{How to dynamically estimate the state (attack-free)?} }
\\ $\underset{\color{red}\text{(copy of the system + correction) }}{\textbf{Luemberger Observer}}$ $\underset{\text{def}}{\Longrightarrow}$ $\begin{cases}
    \hat{x}(k+1)=A\hat{x}(k)-L[\hat{y}(k)-y(k)]\\
    \hat{y}(k)=C\hat{x}(k)
\end{cases}$ $\underset{e(k)=\hat{x}-x}{\longrightarrow}$  $e(k+1)=(A-LC)e(k)$\\
$L$ is the \textbf{observer-gain matrix}, chosen such that $e(k+1)$ is asymptotically stable $\underset{k\to\infty}{\longrightarrow} \hat{x}(k)=x(k)$\\
\textbf{Online Gradient Descent (OGD)}  $L_g=\tau AC^T, \quad \tau \le \Vert C \Vert_2^{-2}$\\

\vspace{-0.3cm}\noindent
{\color{blue}{\textbf{What about the attacks?}}}\\
\textbf{In general} CPSs under attacks are \textbf{not observable} $\longrightarrow$ NO Luemberger Observer, NO OGD\\

\vspace{-0.1cm}
\noindent
\underline{\textbf{SPARSE OBSERVER}} $\overunderset{k \ \text{is the time}}{\text{given} \ \hat{z} \ \text{and}\ y=Gz}{\Longrightarrow}$ $\begin{cases}
    \hat{z}^+(k)=A\hat{z}^(k)-\tau A G^T[G\hat{z}(k)-y(k)] &      \text{estimation (OGD)}\\
    \hat{x}(k+1) = A \hat{x}^{+}(k) & \text{prediction}\\
    \hat{a}(k+1) = \mathbb{S}_{\lambda\tau}[\hat{a}^+(k)] & \text{sparsify the attacks} \\
    \hat{y}(k)=G\hat{z}(k) & \text{measurement}
\end{cases}$\\

\noindent
\textsc{Application: Localization under sensor attacks (with moving targets)}\\

{\color{red} \subsection*{Distributed Secure State Estimation of CPSs \quad\quad {\small{[NO FUSION CENTER]}}}} 

\noindent
\textbf{Multi-agent system} set of systems which cooperate in order to achieve a \textbf{common goal}.\\
\textbf{Agents} $\underset{\text{exchange}}{\Longrightarrow}$ \textbf{local estimate} $x^{(i)}(k)$ $\underset{\text{to the}}{\longrightarrow}$ neighbourhood\\
\textbf{Graph} $\mathcal{G}=(\mathcal{N},\mathcal{E})$ $\rightarrow$ math tool to model the inter-communication. It is made up of:
\begin{itemize}
    \itemsep-0.3em
    \item A set $\mathcal{N}$ of agents or nodes or vertices; 
    \item A set $\mathcal{E}\subseteq\mathcal{N}\times\mathcal{N}$ of links or edges
\end{itemize}
\vspace{-0.4em}
\textbf{Neighbourhood} $\mathcal{N}_i$ $\rightarrow$ set of the nodes from which receives information.\\
\textbf{Local mean} {\normalsize{$\bar{x}^{(i)}(k)=\frac{1}{\vert \mathcal{N}_i \vert} \underset{j\in\mathcal{N}_i}{\sum}{x^{(j)}(k)}$}}\\
\underline{\large\textbf{CONSENSUS}} {\large{$x(k+1)=Qx(k)$}} $\longrightarrow$ the system organized how $Q$ dictates, achieves a \textbf{global common decision} if $Q$ has got some properties.\\
\textbf{Stochastic matrix} $Q$ is stochastic $\iff \forall i=1,...,q \quad \overunderset{q}{j=1}{\sum} Q_{ij}=1$ \textbf{(row stochastic)}\\
\textbf{Doubly stochastic matrix} $Q$ is doubly stochastic $\iff$ is symmetric (undirected graphs)\\
\textbf{Some important results}:
\vspace{-0.2cm}
\begin{itemize}
    \itemsep-0.3em
    \item[$\longrightarrow$] $\lambda_1=\lambda_{PF} > \vert \lambda_2 \vert > ... > \vert \lambda_q \vert \Longrightarrow \underset{k\to\infty}{\lim} x(k)=\alpha\mathbf{1}$ (suff. conditions for Consensus)  
    \item[$\longrightarrow$]  $\lambda_{PF} > \vert \lambda_2 \vert > ... > \vert \lambda_q \vert, $ $Q$ doubly stochastic $ \underset{\text{average 
    consensus}}{\Longrightarrow} \underset{k\to\infty}{\lim} x(k)=\alpha\mathbf{1}, \ \alpha=\frac{1}{q}\overunderset{q}{j=1}{\sum}x^{(j)}(0)$  
    \item[$\longrightarrow$] \textbf{Convergence rate} of the consensus algorithm  $\underset{\text{is related to}}{\longrightarrow}$ \texttt{esr}(Q)=$\lambda_2$ 
    \item[$\longrightarrow$] If $Q^T$=Adjacency matrix describes a strongly connected graph $\Longrightarrow$ $Q$ achieves consensus.
\end{itemize}
\noindent
{\underline{\normalsize\textbf{APPLICATIONS of CONSENSUS ALGORITHM}}}\\
\textbf{\textsf{Distributed Least-Squares}} $\underset{\text{minimize}}{\longrightarrow}$ $F(x)=\Vert y-Ax \Vert_2^2$, each sensor has $\begin{cases}
    y_i & \text{its own \textbf{measurement}}\\
    A_i & i-\text{th row of the matrix A}
\end{cases}$ \\
$\Longrightarrow$ 
$\overset{\textsf{\color{blue}the solution can be found by using...}}{\textbf{Distributed Gradient Descent (DGD)}}$
    $\underset{\color{red}\forall i\in\{1,...,q\}}{\longrightarrow}$
  $ \begin{cases}
    \bar{x}^{(i)}(k)=\sum_{j=1}^{q} Q_{ij}x^{(j)}(k) \\
    x^{(i)}(k+1)=\underbrace{\bar{x}^{(i)}(k)}_\textsf{\color{red} \textbf{consensus} step}-\underbrace{\tau\nabla F(x^{(i)}(k))}_\textsf{\color{red}\textbf{gradient} step}
\end{cases}$

\noindent
\textbf{\textsf{Distributed LASSO}}$\underset{\text{minimize}}{\longrightarrow}$ $F(x)=\Vert y-Ax \Vert_2^2 + \lambda \Vert x \Vert_1$\\
$\Longrightarrow$ 
$\overset{\textsf{\color{blue}the solution can be found by using...}}{\textbf{Distributed ISTA(DISTA)}}$
$\underset{\color{red}\forall i\in\{1,...,q\}}{\longrightarrow}$
{\large{
    $x^{(i)}(k+1)=\mathbb{S}_{\lambda\tau}\big[ 
        \bar{x}^{(i)}(k) +
        \tau A_i^T(y-A_ix^{i}(k))    
    \big]$
}}\\

\noindent
{\small{
    \textbf{Note that...} for these algorithms proofs of convergence have been provided.
}}

%----------------------------------------------------------------
\begin{center}
    \rule{300pt}{.2pt}
    \vspace{-1ex}
\end{center}


\section{Control of Cyber Physical Systems}
\subsection*{\color{red}Introduction}
\textbf{Leader node} $
    \begin{aligned}
        S_0: \ \begin{cases}
            \dot{x}_0=Ax_0\\
            y_0=Cx_0
        \end{cases}
    \end{aligned}$ \qquad
\textbf{Follower nodes} $\begin{aligned}
    S_i=\begin{cases}
        \dot{x}_i=Ax_i+Bu_i\\
        y_i=Cx_i
    \end{cases}
\end{aligned}$ $i=1,...,N$\\
\textbf{Communication network among the agents}
$\mathcal{G} = \{\mathcal{V}, \mathcal{E}\}, \ \mathcal{V}=\{v_1, v_2, ..., v_N\}, \ 
\mathcal{E} \subset \mathcal{V} \times \mathcal{V}$\\
\textbf{Augmented graph(Agents + Leader node)}
$\bar{\mathcal{G}} = \{
    \bar{\mathcal{V}}, \bar{\mathcal{E}}
\}, \ 
\bar{\mathcal{V}}=\{v_0, v_1, ...,v_N\}, \ 
\bar{\mathcal{E}}=\bar{\mathcal{V}} \times \bar{\mathcal{V}}$

\subsection*{\color{red}Agents' experimental modeling (System Identification)}
\textbf{Discrete time domain (LTI)} 
$\begin{aligned}
    &\text{state-space description} &\quad
    &\begin{cases}
        \dot{x}_i(t)=Ax_i(t)+Bu_i(t)\\
        y_i(t)=Cx_i(t)
    \end{cases}\\
    &\text{transfer function description} &\quad
    &H(s)=C(sI-A)^{-1}B
\end{aligned}$\\
\textbf{Continuous time domain (LTI)}
$\begin{aligned}
    &\text{state-space description} &\quad
    &\begin{cases}
        \dot{x}_i(k)=Ax_i(k)+Bu_i(k)\\
        y_i(k)=Cx_i(k)
    \end{cases}\\
    &\text{transfer function description} &\quad
    &H(z)=C(zI-A)^{-1}B
\end{aligned}$ \\

\noindent
\textbf{Regression form}
$y(k)=f(y(k-1), y(k-2), ...,y(k-n), u(k), u(k-1), ..., u(k-m), \theta), \ m\le n$\\

\noindent
\textbf{\color{blue}LEAST-SQUARES APPROACH} \\
\begin{equation*}
    \underbrace{\begin{bmatrix}
    y(3)\\y(4)\\\vdots\\y(H)
\end{bmatrix}}_{y} 
=\underbrace{ 
\begin{bmatrix}
    y(2)&y(1)&u(3)&u(2)&u(1)\\
    y(3)&y(2)&u(4)&u(3)&u(2)\\
    &\vdots&\vdots&\vdots&\vdots\\
    y(H-1)&y(H-2)&u(H)&u(H-1)&u(H-2)
\end{bmatrix}}_{A} \underbrace{\begin{bmatrix}
    \theta_1\\\theta_2\\\vdots\\\theta_H
\end{bmatrix}}_{\theta}\end{equation*}\\
\textbf{Solution of LS: } $\hat{\theta} = A^\dagger y = (A^TA)^{-1}A^T y$ this is the solution of: $ \hat{\theta} = \text{arg}\min_\theta \Vert A\theta-y\Vert_2^2$

\noindent
$\begin{aligned}
    &\textbf{Least Squares properties } 
    \underset{H\to\infty}{\lim} \mathbb{E}\big[\hat{\theta}\big] = \theta\\
    &\textsf{(\small Consistency property)}  
\end{aligned}
$
$\iff$ $\begin{cases}
    \textsf{- The error apper in the equation as an additive  }\\
    \textsf{ term $e(k)$ called the \textbf{equation error (EE)}}\\
    \textsf{- The $e(k) k=1,...,H$ represents a white gaussian }\\
    \textsf{ noise, that is the samples are \textit{indipendent and}}\\
    \textsf{\textit{ identically distributed} (iid)}
\end{cases}$ \\

\noindent
\textbf{\color{blue}SET-MEMBERSHIP APPROACH} [small amount of data + \textbf{mild assumption} on the noise]\\
\textbf{Main ingredients}
$\begin{cases}
     y(k) = f(y(k-1),...,y(k-n), u(k), u(k-1), u(k-m), \theta_1, ..., \theta_{n+m+1}), \quad m \le n\\
    \textsf{(1) A-priori assumption on the system } m,n \text{ known + class of function } \mathcal{F} \ \text{known} \\
    \textsf{A-priori \textbf{assumption on the noise}: Equation Error, Outuput Error, Error-In-Variable}\\
    \textsf{Input/Output noise are \textbf{bounded}} \to \textsf{polynomial constraints} \iff \\
    \mathcal{B}_\eta = \{
                \eta: \ \vert \eta(k) \vert \le \Delta_\eta
            \}, \quad
            \mathcal{B}_\xi = \{
                \xi : \ \vert \xi(k) \vert \le \Delta_\xi
            \} 
    
\end{cases}$        \\

\noindent
\textbf{Feasible Parameter Set (FPS)} \\
\begin{equation*}
    \begin{aligned}
    \mathcal{D}_\theta = &\{
        \theta\in\mathbb{R}^p: \
        y(k)=f(y(k-1), ..., y(k-n), u(k),u(k-1), ..., u(k-m), \theta), \ k=n+1,...,H,\\
        & y(k)=\tilde{y}(k)-\eta(k), \quad 
        u(k)=\tilde{u}(k)-\xi(k), \ k=1, ..., H
        \vert \xi(k) \vert \le \Delta_\xi, \ 
        \vert \eta(k) \vert \le \Delta_\eta, \ 
        k=1,...,H
        \}
\end{aligned}
\end{equation*}

\vspace{0.7em}
\noindent
\textbf{Extended Feasible Parameter Set (EFPS)} {\small{(non convex -set defined by \textbf{polynomial constraints})}}

\begin{equation*}
    \linespread{0.3em}
    \begin{aligned}
        \mathcal{D}_{\theta,\xi,\eta} =&\big\{
            \theta\in\mathbb{R}^p,\ 
            \xi \in \mathbb{R}^H, \
            \eta \in \mathbb{R}^H: \ 
            (\tilde{y}(k)-\eta(k))+ 
            \sum_{i=1}^n {\theta_i (\tilde{y}(k-1)-\eta(k-1))} =\\ &=\sum_{j=0}^m {\theta_j} (u(k-j)-\xi(k-j)), \ k=n+1, ..., H 
            \vert \xi(k) \vert \le \Delta_\xi, \ 
            \vert \eta(k) \vert \le \Delta_\eta, \ 
            k=1,...,H
        \big\}
    \end{aligned}
\end{equation*}

\noindent
\textbf{Parameter Uncertainty Intervals (PUIs)}
$\underline{\theta}_k=\underset{\theta,\xi,\eta\in\mathcal{D_{\theta,\xi,\eta}}}{\min}
 {\theta_k}, \quad \overline{\theta}_k=\underset{\theta,\xi,\eta\in\mathcal{D_{\theta,\xi,\eta}}} {\max}{\theta_k} \label{eq:PUIs}, \ PUI_{\theta_k} =  [\underline{\theta}_k, \overline{\theta}_k]$\\

\noindent
\textbf{Use of PUI} $
\begin{cases}
    \textsf{In the correct form for \textbf{Robust control}: $\mathcal{H}_\infty$, $\mu$-synthesis...}\\
    \textsf{In case we need a single model $\to$ \textbf{central estimate} defined as }
    \theta_k^c = \frac{\underline{\theta}_k+\overline{\theta}_k}{2}\\
    \textsf{\textbf{central estimate}} \iff 
    \textsf{Chebyshev center of $\mathcal{D}_\theta$ in $\ell_\infty$-norm} 
\end{cases}$\\
$\begin{aligned}
    \centering
    &\textbf{Other potentially availale a-priori info}\\
    &{\small{\textsf{(can be encapsulated in EFPS)}}}
\end{aligned}$
$\begin{cases}
    \textsf{DC-GAIN: use of limits } s\to0, \ z\to 1 \textsf{ (linear constraints)}\\
    \textsf{BIBO stability of the system} \to \textsf{enforced with Jury's Theorem}
\end{cases}$\\

\noindent
\textbf{Convex relaxation for PUIs }\\
Original optimization problem $\underset{\textsf{Moment Theory}}{\Longrightarrow}$ Set of SDPs $\underset{\textsf{depends on}}{\leftarrow}$ \textbf{Order of relaxation $\delta$}
\noindent
It holds that:
$\underset{\delta\to\infty}{\lim}  \underline{\theta}_k^\delta = \underline{\theta}_k, \quad
\underset{\delta\to\infty}{\lim} \overline{\theta}_k^\delta = \overline{\theta}_k \quad$ 
\textbf{Computational complexity} $\begin{cases}
    \textsf{Exponential in } \delta\\
    \textsf{Linear in number of parameters}
\end{cases}$\\

\noindent
\textbf{\large\texttt{SparsePOP} data structures}\\
\textbf{Problem of type} $
\begin{aligned}
    \min_{x\in\mathbb{R}^n}  \quad & f_0(x) \ 
        &\text{s.t.} f_k(x)\ge 0 \quad (k=1,...,l), f_k(x)=0 \quad (k=l+1, ..., m), \texttt{lb}_i \le x_i \le \texttt{ub}_i
\end{aligned}$\\
$\begin{aligned}
    &\textbf{Objective function $f_0$ (\texttt{objPoly})} \\
    &\textbf{Constraints $f_k$ (\texttt{ineqPolySys\{k\}})}
\end{aligned}$
$\begin{cases}
    \texttt{typeCone} \to \textsf{1 (equality), -1 (inequality)}\\
    \texttt{dimVar}\to \textsf{\# of opt. variables including those in the constraints}\\
    \texttt{degreee} \to \textsf{degree of $f_0$/$f_k$}\\
    \texttt{noTerms} \to \textsf{number of monomials appearing in $f_0$/$f_k$} \\
    \texttt{supports} \to \textsf{rows=noTerms, columns=dimVar}\\
    \texttt{coef} \to \textsf{coefficients of the polynomial}
\end{cases}$
\\
\noindent
\textbf{Order of relaxation} \texttt{param.relaxOrder}\\
\textbf{Solution refinement} \texttt{param.POPSolver='active-set'}\\
\vspace{-1.5em}
{\color{blue}
\begin{verbatim}
    [param,SDPobjValue,POP,elapsedTime,SDPsolverInfo,SDPinfo]  = ... 
         sparsePOP(objPoly,ineqPolySys,lbd,ubd,param); 
\end{verbatim}
}


%-------------------------------------------------------
\subsection*{\color{red}Distributed optimal cooperative control of multi-agent systems (SVFB)}
\textbf{Cooperative tracking regulator} $\iff$ The leader dictate a behaviour tracked by the agents\\

\noindent
\textbf{Neighbourhood of an agent} $ \mathcal{N}_i = \{j \ | \ a_{ij}>0\} \quad$ \textbf{Pinning matrix}  $G=diag(g_1, g_2, ..., g_N)$\\
\textbf{Neighbourhood tracking error} $ \varepsilon_i = \sum_{j=1}^N {
    a_{ij}(x_j-x_i) + g_i (x_0-x_i)
}$
\textbf{Local controller} $u_i = cK\varepsilon_i$\\
\textbf{Closed-loop system dynamics}
$\dot{x_i} = A x_i + B u_i = A x_i + cBK \biggl(
    \sum_{j=1}^N {
    a_{ij}(x_j-x_i) + g_i (x_0-x_i)
}
\biggr)$
\textbf{Laplacian matrix} $ L=[l_{ij}] = D-\mathcal{A}, \quad
D=diag(d_1, d_2, ..., d_N) $\\

\noindent
\textbf{Global closed-loop dynamics} $ \dot{x} = (I_N \otimes A - c(L+G)\otimes BK)x +
(c(L+G)\otimes BK)\underline{x}_{0}$\\
\textbf{Disagreemnent error} $\begin{cases}
    \textsf{\textbf{Local }}   \delta_i(t) = x_i(t) - {x}_0(t)\\
    \textsf{\textbf{Global }}   \delta(t) = x(t)-\underline{x}_0(t)=col(\delta_1, \delta_2, \dots, \delta_N).
\end{cases}$\\
\textbf{Global disagreement error dynamics} $\begin{aligned}
    &\dot{\delta_t} = \dot{x}(t) - \dot{\underline{x}}_0 = A_c \delta(t), \label{eq:GDE} \\
    &A_c = I_N \otimes A - c(L+G)\otimes BK
\end{aligned}$\\

\noindent
\textbf{\color{blue}Objective of cooperative tracking} 
$\underset{t\to\infty}{\lim}  \delta(t) = 0 \iff
A_c$ is \textbf{Hurwitz}\\
\textbf{Closed-loop eigenvalues} $\text{eig}(A_c) = \bigcup_{i=1}^N \text{eig}(A-c \lambda_iBK)$ where $\lambda_i$ are the eigenvalues of $L+G$\\

\noindent
\textbf{Cooperative controller design ($K, c$)} $\begin{cases}
    K = R^{-1} B^T P,  \quad R \textsf{ properly selected} \textbf{ \small (controller gain matrix)}\\
    P \ \textsf{solution of ARE: } A^T P + PA + Q - PBR^{-1}B^T P = 0\\
    Q, R \ \to  u(t) = \text{arg}\underset{u(t)}{\min}\bigg[
        \frac{1}{2} \int_0^{+\infty} {
            \Vert x(t) \Vert_Q + 
            \Vert u(t) \Vert_R
        } \ dt \bigg] \textsf{\small[opt. LQ]}\\
    c \ge \frac{1} {2 \min_{i\in\mathcal{N}} Re(\lambda_i)} \textbf{ (coupling gain)} 
\end{cases}$\\

\noindent
\textbf{Dynamic of the leader $S_0$} $\quad \dot{x_0}(t) = A x_0(t)- BK'x, \ K'$ in order to have $\begin{cases}
    \textsf{step} \to \textsf{one $\lambda_i=0$}\\
    \textsf{ramp} \to \textsf{two coincident $\lambda_i$}\\
    \textsf{sine} \to \textsf{complex conjugate $\lambda_i$}
\end{cases}$\\

\subsection*{\color{red}Dynamic regulator design for CPSs}
\textbf{\color{blue}\large GLOBAL OBSERVER DESIGN}\\

\noindent
\textbf{Local output estimation error} $ \tilde{y}_i = y_i - \hat{y}_i = y_i - C \hat{x}_i $\\
\textbf{Neighbourhood output estimation error} $\xi_i = \sum_{j=1}^N {a_{ij} (\tilde{y}_j - \tilde{y}_i) + g_i(\tilde{y}_0 - \tilde{y}_i)}$\\
\textbf{Local observer} $\dot{\hat{x}}_i = A \hat{x}_i + B u_i - cF\xi_i$\\
\noindent
\textbf{Global cooperative observer dynamics} 
$\begin{aligned}
    &\dot{\hat{x}}= A_o\hat{x} + 
(I_N \otimes B) u + c ((L+G)\otimes F) y\\
&A_o= (I_N \otimes A) - c ((L+G)\otimes FC)
\end{aligned}$

\noindent
\textbf{Global observer quantities} $\begin{cases}
    \tilde{x}(t) = x(t)-\hat{x}(t) \to \ \textsf{Global state estimation error} \\
    \dot{\tilde{x}}(t) = \dot{x}_i(t) - \dot{\hat{x}}_i(t) = A_o \tilde{x}(t) \to \ \textsf{estimation error dynamics}\\
    \underset{t\to\infty}{\lim} \tilde{x}(t) = 0 \to \ \textsf{Cooperative observer objective} \to A_o \textbf{ Hurwitz}
\end{cases}$\\

\noindent
\textbf{Global Observer eigenvalues} \texttt{to do...} \\

\noindent
\textbf{Global Observer design ($F,c$)} \texttt{to do...}\\

\noindent
\textbf{\color{blue}\large COOPERATIVE DYNAMIC REGULATOR DESIGN} \texttt{to do...}\\

%-------------------------------------------------------
\subsection*{\color{red}Formation control} \texttt{to do...}

\end{document}
